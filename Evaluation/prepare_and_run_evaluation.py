#!/usr/bin/env python3
"""
Prepare predictions and ground-truths for Cell Tracking Challenge evaluation,
run the `SEGMeasure` tool, record the filename mapping, and clean up.

The SEGMeasure tool natively supports both 2D and 3D TIFF images without requiring
any special configuration - it automatically detects the dimensionality from the
TIFF file structure.

Usage example:
  python3 prepare_and_run_evaluation.py \
    --gt /path/to/gt_folder \
    --pred /path/to/pred_folder \
    --eval /path/to/eval/software_or_executable \
    --dataset my_dataset_name \
    --output-dir /path/to/output/results

- create a temporary evaluation folder with structure: <name>_01/01_GT/SEG and 01_RES/
- copy/rename files to the naming convention: man_segXXXX.tif and maskXXXX.tif
- save a JSON mapping of original -> new filenames in results/<dataset>/
- run SEGMeasure (auto-detected inside eval path) and capture its output
- save evaluation results in results/<dataset>/ directory (relative to script location by default)
- capture per-image results if generated by the evaluation software
- delete the temporary folder (unless --keep-temp is specified)
"""

import argparse
import json
import os
import re
import shutil
import subprocess
import sys
import tempfile
from pathlib import Path
import tifffile
from tqdm import tqdm
from calculate_MaP import InstanceSegmentationEvaluator


def find_segmeasure(eval_path: Path):
    # If user passed the executable directly
    if eval_path.is_file() and os_access_exec(eval_path):
        return str(eval_path)

    # If a directory was passed, look for SEGMeasure inside
    if eval_path.is_dir():
        candidate = eval_path / 'SEGMeasure'
        if candidate.exists() and os_access_exec(candidate):
            return str(candidate)
    return None


def os_access_exec(p: Path):
    try:
        return p.exists() and os.access(str(p), os.X_OK)
    except Exception:
        return False


def extract_last_number(stem: str):
    m = re.search(r"(\d+)(?!.*\d)", stem)
    if m:
        return int(m.group(1))
    return None


def detect_image_dimensionality(image_path: Path):
    """
    Detect if a TIFF image is 2D or 3D for informational purposes.
    
    Note: The SEGMeasure evaluation software automatically handles both 2D and 3D
    images without requiring special configuration. This function is just for
    providing informative output to the user.
    
    Args:
        image_path: Path to the TIFF file
        
    Returns:
        str: '2D' or '3D' based on image dimensions
    """
    try:
        with tifffile.TiffFile(image_path) as tif:
            # Get the shape of the first page/series
            if len(tif.pages) > 1:
                # Multiple pages typically indicate 3D stack
                return '3D'
            else:
                # Single page - check the shape
                shape = tif.pages[0].shape
                if len(shape) == 2 or (len(shape) == 3 and shape[2] <= 4):
                    # 2D image (H, W) or 2D with channels (H, W, C)
                    return '2D'
                else:
                    # 3D image
                    return '3D'
    except Exception as e:
        print(f"Warning: Could not determine dimensionality of {image_path}: {e}")
        # Default to 2D as fallback
        return '2D'


def calculate_map_metrics(gt_seg_dir: Path, res_dir: Path) -> dict:
    """
    Calculate mean Average Precision (mAP) metrics using the MaP calculator.
    
    Args:
        gt_seg_dir: Directory containing ground truth segmentation files (man_segXXXX.tif)
        res_dir: Directory containing prediction files (maskXXXX.tif)
        
    Returns:
        Dictionary with mAP results
    """
    try:
        evaluator = InstanceSegmentationEvaluator()
        
        # Get all ground truth files
        gt_files = sorted(gt_seg_dir.glob("man_seg*.tif"))
        
        if not gt_files:
            print("Warning: No ground truth files found for mAP calculation")
            return {}
        
        all_results = []
        
        for gt_file in tqdm(gt_files, desc="Calculating mAP", unit="image"):
            # Extract frame number from man_segXXXX.tif
            frame_num = gt_file.stem.replace('man_seg', '')
            pred_file = res_dir / f"mask{frame_num}.tif"
            
            if not pred_file.exists():
                print(f"Warning: No prediction found for {gt_file.name}")
                continue
            
            results = evaluator.evaluate_files(str(pred_file), str(gt_file))
            results['filename'] = gt_file.name
            all_results.append(results)
        
        # Aggregate results
        if not all_results:
            return {}
        
        aggregated = {
            'mAP': sum(r['mAP'] for r in all_results) / len(all_results),
            'AP50': sum(r['AP50'] for r in all_results) / len(all_results),
            'AP75': sum(r['AP75'] for r in all_results) / len(all_results),
            'total_pred': sum(r['n_pred'] for r in all_results),
            'total_gt': sum(r['n_gt'] for r in all_results),
            'n_images': len(all_results),
            'per_image_results': all_results
        }
        
        return aggregated
        
    except Exception as e:
        print(f"Error calculating mAP: {e}")
        return {}


def prepare_temp_structure(gt_dir: Path, pred_dir: Path, seg_exec: str, dataset_name: str,
                           seq='01', digits=4, keep_temp=False, output_dir: Path = None):
    # Create temp dir
    tmp = Path(tempfile.mkdtemp(prefix='ctc_eval_'))
    dataset_dir = tmp / f"{dataset_name}_{seq}"
    gt_seg_dir = dataset_dir / f"{seq}_GT" / "SEG"
    res_dir = dataset_dir / f"{seq}_RES"
    gt_seg_dir.mkdir(parents=True, exist_ok=True)
    res_dir.mkdir(parents=True, exist_ok=True)

    pred_files = sorted([p for p in pred_dir.iterdir() if p.suffix.lower() in ('.tif', '.tiff')])
    gt_files = {p.name: p for p in gt_dir.iterdir() if p.suffix.lower() in ('.tif', '.tiff')}
    
    # Detect and report dimensionality for informational purposes
    # Note: SEGMeasure automatically handles both 2D and 3D images
    if pred_files:
        dimensionality = detect_image_dimensionality(pred_files[0])
        print(f"\n[INFO] Detected image dimensionality: {dimensionality}")
        print(f"[INFO] SEGMeasure will automatically process {dimensionality} images\n")

    mapping = []
    used_numbers = set()
    seq_counter = 0

    for p in pred_files:
        pred_stem = p.stem.replace('_masks', '')
        # Find GT candidate by exact stem first
        gt_candidate = None
        for ext in ('.tif', '.tiff'):
            cand = gt_dir / f"{pred_stem}{ext}"
            if cand.exists():
                gt_candidate = cand
                break

        # If not found, try substring match
        if gt_candidate is None:
            for g in gt_dir.iterdir():
                if g.is_file() and pred_stem in g.stem:
                    gt_candidate = g
                    break

        # If still not found, try to match numeric frame
        frame = extract_last_number(pred_stem)
        if gt_candidate is None and frame is not None:
            # look for gt file containing same number (with or without leading zeros)
            frame_str = str(frame)
            for g in gt_dir.iterdir():
                if g.is_file() and frame_str in g.stem:
                    gt_candidate = g
                    break

        # Ensure unique numeric id for output file
        if frame is None:
            # fallback to sequential counter
            while seq_counter in used_numbers:
                seq_counter += 1
            frame = seq_counter
            seq_counter += 1

        # If number collides, find next free
        if frame in used_numbers:
            # increment until free
            original = frame
            while frame in used_numbers:
                frame += 1
        used_numbers.add(frame)

        mask_name = f"mask{frame:0{digits}d}.tif"
        seg_name = f"man_seg{frame:0{digits}d}.tif"

        dest_pred = res_dir / mask_name
        shutil.copy2(p, dest_pred)

        if gt_candidate is not None:
            dest_gt = gt_seg_dir / seg_name
            shutil.copy2(gt_candidate, dest_gt)
            gt_path_str = str(gt_candidate)
        else:
            dest_gt = None
            gt_path_str = None

        mapping.append({
            'original_pred': str(p),
            'original_gt': gt_path_str,
            'new_pred': str(dest_pred),
            'new_gt': str(dest_gt) if dest_gt else None,
            'frame': frame,
        })

    # write mapping to temp first
    mapping_file_temp = tmp / 'mapping.json'
    with mapping_file_temp.open('w') as f:
        json.dump(mapping, f, indent=2)

    # Run evaluation
    eval_log_temp = tmp / 'eval_log.txt'
    # SEGMeasure usage: SEGMeasure <dir> <seq> <num_digits>
    cmd = [seg_exec, str(dataset_dir), seq, str(digits)]
    print('Running:', ' '.join(cmd))
    with eval_log_temp.open('w') as lf:
        proc = subprocess.run(cmd, stdout=lf, stderr=subprocess.STDOUT)

    print(f"SEGMeasure exit code: {proc.returncode}")
    
    # Read and display evaluation results
    log_content = ""
    if eval_log_temp.exists():
        print("\n=== SEGMeasure Results ===")
        with eval_log_temp.open('r') as f:
            log_content = f.read()
            print(log_content)
        print("=" * 30)
    
    # Calculate mAP metrics
    print("\n=== Calculating mAP metrics ===")
    map_results = calculate_map_metrics(gt_seg_dir, res_dir)
    
    if map_results:
        print(f"mAP: {map_results['mAP']:.6f}")
        print(f"AP@0.50: {map_results['AP50']:.6f}")
        print(f"AP@0.75: {map_results['AP75']:.6f}")
        print(f"Images evaluated: {map_results['n_images']}")
        print(f"Total predictions: {map_results['total_pred']}")
        print(f"Total ground truth: {map_results['total_gt']}")
        print("=" * 30)
        
        # Append mAP results to log content
        map_content = "\n\n=== mAP Metrics ===\n"
        map_content += f"mAP: {map_results['mAP']:.6f}\n"
        map_content += f"AP@0.50: {map_results['AP50']:.6f}\n"
        map_content += f"AP@0.75: {map_results['AP75']:.6f}\n"
        map_content += f"Images evaluated: {map_results['n_images']}\n"
        map_content += f"Total predicted instances: {map_results['total_pred']}\n"
        map_content += f"Total ground truth instances: {map_results['total_gt']}\n"
        
        # Add per-image results if available
        if 'per_image_results' in map_results and map_results['per_image_results']:
            map_content += "\n=== Per-Image mAP Results ===\n"
            for img_result in map_results['per_image_results']:
                map_content += f"\n{img_result['filename']}:\n"
                map_content += f"  mAP: {img_result['mAP']:.6f}\n"
                map_content += f"  AP@0.50: {img_result['AP50']:.6f}\n"
                map_content += f"  AP@0.75: {img_result['AP75']:.6f}\n"
                map_content += f"  Predicted instances: {img_result['n_pred']}\n"
                map_content += f"  Ground truth instances: {img_result['n_gt']}\n"
        
        log_content += map_content
        
        # Write updated log content (SEGMeasure + mAP) back to file
        with eval_log_temp.open('w') as f:
            f.write(log_content)
    else:
        print("Warning: Could not calculate mAP metrics")
        print("=" * 30)

    # Check for per-image results in the RES folder
    per_image_results = {}
    res_folder = dataset_dir / f"{seq}_RES"
    if res_folder.exists():
        # Look for any CSV, TXT, or other result files
        for result_file in res_folder.glob("*"):
            if result_file.is_file() and result_file.suffix.lower() in ['.txt', '.csv', '.log']:
                try:
                    with result_file.open('r') as rf:
                        per_image_results[result_file.name] = rf.read()
                except Exception as e:
                    print(f"Warning: Could not read {result_file.name}: {e}")

    # Copy results to output directory if specified
    if output_dir:
        output_dir.mkdir(parents=True, exist_ok=True)
        mapping_file = output_dir / 'mapping.json'
        eval_log = output_dir / 'evaluation_results.txt'
        map_results_file = output_dir / 'map_results.json'
        
        shutil.copy2(mapping_file_temp, mapping_file)
        shutil.copy2(eval_log_temp, eval_log)
        
        # Save mAP results as JSON if available
        if map_results:
            with map_results_file.open('w') as f:
                json.dump(map_results, f, indent=2)
        
        # Copy any result files from the temporary RES folder (excluding image files)
        if res_folder.exists():
            for result_file in res_folder.glob("*"):
                if result_file.is_file():
                    # Skip image files (tif, tiff, png, jpg, jpeg)
                    if result_file.suffix.lower() not in ['.tif', '.tiff', '.png', '.jpg', '.jpeg']:
                        dest = output_dir / result_file.name
                        shutil.copy2(result_file, dest)
        
        print(f"Results saved to: {output_dir}")
        print(f"  - Mapping: {mapping_file}")
        print(f"  - Evaluation log: {eval_log}")
        if map_results:
            print(f"  - mAP results: {map_results_file}")
    else:
        mapping_file = mapping_file_temp
        eval_log = eval_log_temp

    # Optionally keep or cleanup
    if keep_temp:
        print(f"Temporary evaluation folder preserved at: {tmp}")
        return proc.returncode, tmp, mapping_file, eval_log
    else:
        # remove the temp dir
        try:
            shutil.rmtree(tmp)
        except Exception as e:
            print(f"Warning: failed to remove temp dir {tmp}: {e}")
        return proc.returncode, None, mapping_file, eval_log


def main():
    parser = argparse.ArgumentParser(description='Prepare and run CTC SEGMeasure on GT and predictions')
    parser.add_argument('--gt', required=True, help='Path to ground truth folder')
    parser.add_argument('--pred', required=True, help='Path to predictions folder')
    parser.add_argument('--eval', required=True, help='Path to evaluation software directory or SEGMeasure executable')
    parser.add_argument('--dataset', required=True, help='Dataset name for organizing results')
    parser.add_argument('--output-dir', help='Output directory for results (default: results/<dataset> in script directory)')
    parser.add_argument('--name', default='TMP', help='Base dataset name to create (default: TMP)')
    parser.add_argument('--seq', default='01', help='Sequence id to use (default: 01)')
    parser.add_argument('--digits', type=int, default=4, help='Zero-padding digits for output filenames (default: 4)')
    parser.add_argument('--keep-temp', action='store_true', help='Do not delete temporary folder after run')
    args = parser.parse_args()

    gt_dir = Path(args.gt)
    pred_dir = Path(args.pred)
    eval_path = Path(args.eval)

    if not gt_dir.exists() or not gt_dir.is_dir():
        print('GT path not found or not a directory:', gt_dir)
        sys.exit(2)
    if not pred_dir.exists() or not pred_dir.is_dir():
        print('Predictions path not found or not a directory:', pred_dir)
        sys.exit(2)

    seg_exec = find_segmeasure(eval_path)
    if seg_exec is None:
        print('SEGMeasure executable not found inside provided eval path:', eval_path)
        sys.exit(3)

    # Determine output directory
    if args.output_dir:
        results_dir = Path(args.output_dir)
    else:
        # Default: store in results/<dataset> relative to this script's location
        script_dir = Path(__file__).parent.resolve()
        results_dir = script_dir / 'results' / args.dataset
    
    code, tmpdir, mapping_file, log_file = prepare_temp_structure(
        gt_dir, pred_dir, seg_exec, dataset_name=args.name, seq=args.seq, 
        digits=args.digits, keep_temp=args.keep_temp, output_dir=results_dir
    )

    if code != 0:
        print('Evaluation returned non-zero exit code:', code)

    # Print locations (mapping/log) if preserved
    if tmpdir:
        print('Temporary dir:', tmpdir)
    print('Mapping file (or path that was removed):', mapping_file)
    print('Evaluation log (or path that was removed):', log_file)
    sys.exit(code)


if __name__ == '__main__':
    main()
